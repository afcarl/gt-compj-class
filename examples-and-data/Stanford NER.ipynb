{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entity recognition\n",
    "=========\n",
    "\n",
    "The *Editor* demo uses named entity recognition (NER) to identify people, places, and organizations in text.\n",
    "\n",
    "Here we'll try to use the Stanford NER system to do this ourselves.\n",
    "\n",
    "To do this, we need to get model files from here: http://nlp.stanford.edu/software/CRF-NER.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger #NLTK has a wrapper for Stanford NER\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "javapath = '/usr/bin/java'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Found /usr/bin/java: /usr/bin/java]\n"
     ]
    }
   ],
   "source": [
    "# apparently nltk wants to use /usr/lib/jvm/default-java instead, and that's out of date.\n",
    "# this fixed that.\n",
    "nltk.internals.config_java(bin=javapath)\n",
    "os.environ['JAVAHOME'] = javapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling the tagger, argument 1 is the model file, and argument 2 is the jarfile for the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger = StanfordNERTagger('/home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                          '/home/jacobe/stanford-ner-2015-12-09/stanford-ner-3.6.0.jar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this example paragraph from http://www.scientificamerican.com/article/apple-fears-court-order-will-open-pandora-s-box-for-iphone-security-video11/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para = 'As U.S. law enforcement escalates its battle to keep criminals from concealing their communication on digital devices or “going dark,” Apple CEO Tim Cook is digging in his heels in resisting government directives to support their investigations. A federal judge in California on Tuesday ordered Apple to step up efforts to help the FBI search the locked iPhone 5c used by Syed Rizwan Farook, who, along with wife Tashfeen Malik, is suspected of a mass shooting at a December 2 holiday party last year in San Bernardino, Calif., that killed 14 people and injured 22. Cook quickly countered the court action with an open letter posted to his company’s site suggesting that the FBI’s request could open a Pandora’s box that undermines security on all iPhones.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As U.S. law enforcement escalates its battle to keep criminals from concealing their communication on digital devices or “going dark,” Apple CEO Tim Cook is digging in his heels in resisting government directives to support their investigations. A federal judge in California on Tuesday ordered Apple to step up efforts to help the FBI search the locked iPhone 5c used by Syed Rizwan Farook, who, along with wife Tashfeen Malik, is suspected of a mass shooting at a December 2 holiday party last year in San Bernardino, Calif., that killed 14 people and injured 22. Cook quickly countered the court action with an open letter posted to his company’s site suggesting that the FBI’s request could open a Pandora’s box that undermines security on all iPhones.\n"
     ]
    }
   ],
   "source": [
    "print para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFClassifier invoked on Tue Feb 23 14:02:21 EST 2016 with arguments:\n",
      "   -loadClassifier /home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz -textFile /tmp/tmprcL0b_ -outputFormat slashTags -tokenizerFactory edu.stanford.nlp.process.WhitespaceTokenizer -tokenizerOptions \"tokenizeNLs=false\" -encoding utf8\n",
      "tokenizerFactory=edu.stanford.nlp.process.WhitespaceTokenizer\n",
      "tokenizerOptions=\"tokenizeNLs=false\"\n",
      "loadClassifier=/home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz\n",
      "encoding=utf8\n",
      "textFile=/tmp/tmprcL0b_\n",
      "outputFormat=slashTags\n",
      "Exception in thread \"main\" java.lang.NoClassDefFoundError: org/slf4j/LoggerFactory\n",
      "\tat edu.stanford.nlp.io.IOUtils.<clinit>(IOUtils.java:42)\n",
      "\tat edu.stanford.nlp.ie.AbstractSequenceClassifier.loadClassifier(AbstractSequenceClassifier.java:1484)\n",
      "\tat edu.stanford.nlp.ie.AbstractSequenceClassifier.loadClassifierNoExceptions(AbstractSequenceClassifier.java:1497)\n",
      "\tat edu.stanford.nlp.ie.crf.CRFClassifier.main(CRFClassifier.java:3015)\n",
      "Caused by: java.lang.ClassNotFoundException: org.slf4j.LoggerFactory\n",
      "\tat java.net.URLClassLoader$1.run(URLClassLoader.java:372)\n",
      "\tat java.net.URLClassLoader$1.run(URLClassLoader.java:361)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat java.net.URLClassLoader.findClass(URLClassLoader.java:360)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n",
      "\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n",
      "\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n",
      "\t... 4 more\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Java command failed : ['/usr/bin/java', '-mx1000m', '-cp', '/home/jacobe/stanford-ner-2015-12-09/stanford-ner-3.6.0.jar', 'edu.stanford.nlp.ie.crf.CRFClassifier', '-loadClassifier', '/home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz', '-textFile', '/tmp/tmprcL0b_', '-outputFormat', 'slashTags', '-tokenizerFactory', 'edu.stanford.nlp.process.WhitespaceTokenizer', '-tokenizerOptions', '\"tokenizeNLs=false\"', '-encoding', 'utf8']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-4775a97e4415>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/tag/stanford.pyc\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# This function should return list of tuple rather than list of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/tag/stanford.pyc\u001b[0m in \u001b[0;36mtag_sents\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Run the tagger and get the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         stanpos_output, _stderr = java(cmd, classpath=self._stanford_jar,\n\u001b[1;32m---> 89\u001b[1;33m                                                        stdout=PIPE, stderr=PIPE)\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[0mstanpos_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstanpos_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/nltk/__init__.pyc\u001b[0m in \u001b[0;36mjava\u001b[1;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_decode_stdoutdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Java command failed : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Java command failed : ['/usr/bin/java', '-mx1000m', '-cp', '/home/jacobe/stanford-ner-2015-12-09/stanford-ner-3.6.0.jar', 'edu.stanford.nlp.ie.crf.CRFClassifier', '-loadClassifier', '/home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz', '-textFile', '/tmp/tmprcL0b_', '-outputFormat', 'slashTags', '-tokenizerFactory', 'edu.stanford.nlp.process.WhitespaceTokenizer', '-tokenizerOptions', '\"tokenizeNLs=false\"', '-encoding', 'utf8']"
     ]
    }
   ],
   "source": [
    "tagger.tag(para.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell version ##\n",
    "\n",
    "I couldn't get NLTK's wrapper to work in time for class, so here's how to do it on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sample.txt','w') as fout:\n",
    "    print >>fout, para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As/O U.S./LOCATION law/O enforcement/O escalates/O its/O battle/O to/O keep/O criminals/O from/O concealing/O their/O communication/O on/O digital/O devices/O or/O ``/O going/O dark/O ,/O ''/O Apple/O CEO/O Tim/PERSON Cook/PERSON is/O digging/O in/O his/O heels/O in/O resisting/O government/O directives/O to/O support/O their/O investigations/O ./O \n",
      "A/O federal/O judge/O in/O California/LOCATION on/O Tuesday/O ordered/O Apple/ORGANIZATION to/O step/O up/O efforts/O to/O help/O the/O FBI/ORGANIZATION search/O the/O locked/O iPhone/O 5c/O used/O by/O Syed/PERSON Rizwan/PERSON Farook/PERSON ,/O who/O ,/O along/O with/O wife/O Tashfeen/PERSON Malik/PERSON ,/O is/O suspected/O of/O a/O mass/O shooting/O at/O a/O December/O 2/O holiday/O party/O last/O year/O in/O San/LOCATION Bernardino/LOCATION ,/O Calif./LOCATION ,/O that/O killed/O 14/O people/O and/O injured/O 22/O ./O \n",
      "Cook/PERSON quickly/O countered/O the/O court/O action/O with/O an/O open/O letter/O posted/O to/O his/O company/O 's/O site/O suggesting/O that/O the/O FBI/ORGANIZATION 's/O request/O could/O open/O a/O Pandora/PERSON 's/O box/O that/O undermines/O security/O on/O all/O iPhones/O ./O \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRFClassifier invoked on Tue Feb 23 14:02:23 EST 2016 with arguments:\n",
      "   -loadClassifier /home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz -textFile sample.txt\n",
      "loadClassifier=/home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz\n",
      "textFile=sample.txt\n",
      "Loading classifier from /home/jacobe/stanford-ner-2015-12-09/classifiers/english.all.3class.distsim.crf.ser.gz ... done [2.3 sec].\n",
      "CRFClassifier tagged 140 words in 3 documents at 1206.90 words per second.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "/home/jacobe/stanford-ner-2015-12-09/ner.sh sample.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
